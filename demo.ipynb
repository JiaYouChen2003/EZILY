{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('key.txt', \"r\") as file:\n",
    "    api_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justin041510\\anaconda3\\envs\\EZILY\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\justin041510\\anaconda3\\envs\\EZILY\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\justin041510\\anaconda3\\envs\\EZILY\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\justin041510\\anaconda3\\envs\\EZILY\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import torchvision\n",
    "import google.generativeai as genai\n",
    "import tqdm\n",
    "\n",
    "from fixed_prompts import classification_p, description_p, class_ps, class_ps_super\n",
    "from cross_modal_encoder import encoder\n",
    "import cifar_100_label\n",
    "import food_101_label\n",
    "\n",
    "\n",
    "def gemini_process(prompt, image=None, temperature=0.99):\n",
    "    \"\"\"\n",
    "    Uses Gemini Pro to generate text based on a prompt, optionally with an image.\n",
    "    Args:\n",
    "    prompt: The text prompt for Gemini Pro.\n",
    "    image_path: Path to the input image (optional).\n",
    "    temperature: Sampling temperature for generating diverse responses.\n",
    "    Returns:\n",
    "    The generated response as a string.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
    "    \n",
    "    input_content = [prompt]\n",
    "    \n",
    "    if image is not None:\n",
    "        try:\n",
    "            input_content.append(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")\n",
    "            return None\n",
    "\n",
    "    response = model.generate_content(\n",
    "        contents=input_content,\n",
    "        generation_config={\"temperature\": temperature, \"max_output_tokens\": 256}\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # print(f'Prompt: {prompt}\\nResponse: {response.candidates[0].content.parts[0].text}')\n",
    "        # Quota: 15 rpm; this should be fine\n",
    "        time.sleep(4 + random.random())\n",
    "        return response.candidates[0].content.parts[0].text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in response generation: {e}\")\n",
    "        return prompt\n",
    "\n",
    "\n",
    "def create_classifier(class_names, use_super_class=False, k=5):\n",
    "    \"\"\"\n",
    "    Constructs a zero-shot image classifier.\n",
    "    Args:\n",
    "    class_names: A list of class names.\n",
    "    class_ps: A list of prompt templates for generating class descriptions.\n",
    "    k: Number of class descriptions to be generated by the LLM.\n",
    "    Returns:\n",
    "    A zero-shot image classification model.\n",
    "    \"\"\"\n",
    "    if k != 0:\n",
    "        assert k >= len(class_ps), \"k should be greater than or equal to the number of class prompts.\"\n",
    "        assert k % len(class_ps) == 0, \"k should be a multiple of the number of class prompts.\"\n",
    "\n",
    "    weights = []\n",
    "    for class_name in tqdm.tqdm(class_names):\n",
    "        class_name_feature = encoder.encode_text(class_name)\n",
    "        template_feature = encoder.encode_text(f\"A photo of {class_name}\")\n",
    "        llm_class_description = torch.zeros((1, encoder.output_feature_length))\n",
    "\n",
    "        if k != 0:\n",
    "            if use_super_class:\n",
    "                for _ in range(k // len(class_ps_super)):\n",
    "                    for class_p in class_ps_super:\n",
    "                        llm_description = gemini_process(class_p.format(class_name=class_name,\n",
    "                                                                        super_class_name=cifar_100_label.get_superclass_label(class_name)), temperature=0.99)\n",
    "                        llm_class_description += encoder.encode_text(llm_description)\n",
    "            else:\n",
    "                for _ in range(k // len(class_ps)):\n",
    "                    for class_p in class_ps:\n",
    "                        llm_description = gemini_process(class_p.format(class_name=class_name), temperature=0.99)\n",
    "                        llm_class_description += encoder.encode_text(llm_description)\n",
    "\n",
    "            llm_class_description /= k\n",
    "\n",
    "        class_feature = class_name_feature + template_feature + llm_class_description\n",
    "        normalized_class_feature = class_feature / class_feature.norm(dim=-1, keepdim=True)\n",
    "        weights.append(normalized_class_feature.squeeze())\n",
    "\n",
    "    weights = torch.stack(weights)\n",
    "    model = {\"weights\": weights.T, \"class_names\": class_names}\n",
    "    return model\n",
    "\n",
    "\n",
    "def classify(image, classifier, use_llm=True):\n",
    "    \"\"\"\n",
    "    Performs zero-shot image classification.\n",
    "    Args:\n",
    "    image: Input testing image.\n",
    "    classifier: A zero-shot classification model generated by create_classifier function.\n",
    "    classification_p: Prompt template for generating the initial classification prediction.\n",
    "    description_p: Prompt template for generating an image description.\n",
    "    Returns:\n",
    "    Predicted class name.\n",
    "    \"\"\"\n",
    "    image_feature = encoder.encode_image(image)\n",
    "\n",
    "    if use_llm:\n",
    "        # Gemini Pro for initial classification prediction\n",
    "        prompt = classification_p.format(classes=classifier[\"class_names\"])\n",
    "        initial_prediction = gemini_process(prompt, image, temperature=0.99)\n",
    "        print(f'Prompt:\\n{prompt}\\nResponse:\\n{initial_prediction}')\n",
    "        prediction_feature = encoder.encode_text(initial_prediction)\n",
    "\n",
    "        # Gemini Pro for generating image description\n",
    "        prompt = description_p\n",
    "        image_description = gemini_process(prompt, image, temperature=0.99)\n",
    "        print(f'Prompt:\\n{prompt}\\nResponse:\\n{image_description}')\n",
    "        description_feature = encoder.encode_text(image_description)\n",
    "\n",
    "        query_feature = image_feature + prediction_feature + description_feature\n",
    "    else:\n",
    "        query_feature = image_feature\n",
    "\n",
    "    query_feature /= query_feature.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    logits = torch.matmul(query_feature, classifier[\"weights\"])\n",
    "    index = torch.argmax(logits, dim=-1)\n",
    "    return classifier[\"class_names\"][index.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: You are given an image and a list of class labels. Classify the image given the class labels. Answer using a single word if possible. Here are the class labels: ['apple_pie', 'baby_back_ribs', 'baklava']\n",
      "Response: Baklava\n",
      "Prompt: What do you see? Describe any object precisely, including its type or class.\n",
      "Response: Here is a description of the object in the image:\n",
      "\n",
      "The image shows a piece of what appears to be a baked dessert, possibly a crumble or clafoutis, on a white plate. \n",
      "\n",
      "\n",
      "**Type/Class:** The dessert is a type of baked confection.  More specifically, it looks like a fruit crumble or a similar type of dessert with a crisp, browned topping and a soft, possibly custardy interior.  The precise type cannot be determined definitively from the image.\n",
      "\n",
      "\n",
      "**Description:** The dessert is roughly triangular in shape, with a golden-brown, slightly irregular surface suggesting a crumbly texture.  A dollop of whipped cream, white and smooth in appearance, is placed on top of it. A small sprig of fresh mint is nestled into the cream. The dessert appears warm and moist. The plate is round, off-white, and relatively plain.  The lighting suggests an indoor setting.\n",
      "\n",
      "Predicted Label: baklava\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.Food101(\n",
    "    root='./food-101',\n",
    "    split='test',\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "labels = ['apple_pie', 'baby_back_ribs', 'baklava']\n",
    "print(f\"Creating classifier with label {labels}\")\n",
    "classifier = create_classifier(class_names=labels, k=10)\n",
    "torch.save(classifier, f\"zero_shot_classifier_demo.pth\")\n",
    "\n",
    "img = Image.open('food-101/food-101/images/apple_pie/64846.jpg').convert(\"RGB\")\n",
    "predicted_label = classify(img, classifier)\n",
    "print(\"Predicted Label:\", predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EZILY",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
